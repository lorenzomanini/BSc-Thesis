\section{Quantum mechanics}
\subsection{The postulates of quantum mechanics} \label{sec:postulates}
Quantum mechanics is a fundamental theory that provides a mathematical framework for modeling the states and evolution of physical systems, as well as predicting the results of observations. In this section, we will state the postulates of quantum mechanics, roughly following the treatment in \ref{chuang}.

\begin{postulate}[The Hilbert space]
    Any isolated physical system is associated with a complex \emph{Hilbert space} i.e.\ a, possibly infinite-dimensional, complex vector space $\mathcal{H}$ with an inner product $\langle\cdot,\cdot\rangle$ that is also complete with respect to the metric induced by the inner product.
\end{postulate}

If the Hilbert space is finite-dimensional with dimension $N$, then it is isomorphic to $\mathbb{C}^N$ with a hermitian form as the inner product. In what follows we will only study systems that are associated with a finite-dimensional Hilbert space.

The chosen inner product allows us to define a canonical isomorphism between $\mathcal{H}$ and its dual vector space $\mathcal{H}^*$, where for every $\mathbf{Z}\in\mathcal{H}$ its dual functional is defined as
\begin{equation} \label{eq:duality}
    \mathbf{Z}^*\equiv f_{\mathbf{Z}}:\mathcal{H}\to\mathbb{C} \quad f_{\mathbf{Z}}(\mathbf{X})=\langle\mathbf{Z},\mathbf{X}\rangle \qquad \forall\, \mathbf{X}\in\mathcal{H}
\end{equation}
We also define tensors $T$ of type $\binom{p}{q}$ as multilinear maps
\begin{equation}
    T:{\mathcal{H}^*}^p\times\mathcal{H}^q \to \mathbb{C}
\end{equation}
where vectors can be identified with tensors of type $\binom{1}{0}$ and dual vectors with tensors of type $\binom{0}{1}$. Operators, which are linear maps from $\mathcal{H}$ to itself, can be identified with $\binom{1}{1}$ tensors. For any operator $A$, the corresponding tensor $T_A$ is defined as
\begin{equation}
    T_A(\mathbf{X}^*,\mathbf{Y})=\mathbf{X}^*(A\mathbf{Y})=\braket{\mathbf{X},A\mathbf{Y}}
\end{equation}
The tensor product $\otimes$ between two tensors $T$ and $T'$ of type $\binom{p}{q}$ and $\binom{p'}{q'}$ is a tensor of type $\binom{p+p'}{q+q'}$ defined as
\begin{align*}
    &(T\otimes T')(\mathbf{X}^*_1,\dots,\mathbf{X}^*_{p+p'},\mathbf{Y}_1,\dots,\mathbf{Y}_{q+q'}) \\
    &= T(\mathbf{X}^*_1,\dots,\mathbf{X}^*_{p},\mathbf{Y}_1,\dots,\mathbf{Y}_{q}) \cdot T'(\mathbf{X}^*_{p+1},\dots,\mathbf{X}^*_{p+p'},\mathbf{Y}_{q+1},\dots,\mathbf{Y}_{q+q'})
\end{align*}
In particular, given a vector $\mathbf{Y}$ and a dual vector $\mathbf{X}^*$, their tensor product is the operator
\begin{equation} \label{eq:outer-prod}
    A(\mathbf{Z})=\mathbf{X}^*(\mathbf{Z})\cdot \mathbf{Y}=\braket{\mathbf{X},\mathbf{Z}}\cdot \mathbf{Y}
\end{equation}

The adjoint of any operator $\mathrm{A}$ is the operator $\mathrm{A}^\dag$ such that
\begin{equation} \label{eq:adjoint}
    \langle\mathrm{A}^\dag\,\mathbf{X},\mathbf{Y}\rangle=\langle\mathbf{X},\mathrm{A}\,\mathbf{Y}\rangle \qquad \forall\, \mathbf{X},\mathbf{Y}\in\mathcal{H}
\end{equation}
It can be shown that this is always well-defined for finite-dimensional Hilbert spaces and that $(\mathrm{A}^\dag)^\dag=\mathrm{A}$. There are two families of operators that will be instrumental to the formulation of the remaining postulates: unitary operators and self-adjoint operators. Unitary operators are defined as operators U that preserve the inner product, i.e.
\begin{equation}
    \braket{\mathrm{U}\mathbf{X},\mathrm{U}\mathbf{Y}}=\braket{\mathbf{X},\mathbf{Y}}\qquad \forall \mathbf{X},\mathbf{Y}\in\mathcal{H}
\end{equation}
From \cref{eq:adjoint}, it's easy to show that
\begin{equation}
    \textit{U is unitary} \iff \mathrm{U}\mathrm{U}^\dag=\mathbb{I}\textit{ i.e }\mathrm{U}^{-1}=\mathrm{U}^\dag
\end{equation}
from which also follows $\mathrm{U}\mathrm{U}^\dag=\mathrm{U}^\dag\mathrm{U}$. Self-adjoint operators are defined as operators A that are equal to their adjoint, i.e.
\begin{equation} \label{eq:selfadj}
    \langle\mathrm{A}\,\mathbf{X},\mathbf{Y}\rangle=\langle\mathbf{X},\mathrm{A}\,\mathbf{Y}\rangle \qquad \forall\, \mathbf{X},\mathbf{Y}\in\mathcal{H}
\end{equation}
or, equivalently, $\mathrm{A}=\mathrm{A}^\dag$. From their definition follows immediately that
\begin{equation} \label{eq:selfadj-real}
    \langle\mathrm{A}\,\mathbf{X},\mathbf{X}\rangle=\overline{\langle\mathbf{X},\mathrm{A}\,\mathbf{X}\rangle}=\overline{\langle\mathrm{A}\,\mathbf{X},\mathbf{X}\rangle}\in\mathbb{R}\qquad \forall\, \mathbf{X}\in\mathcal{H}
\end{equation}

We can now state the remaining postulates of quantum mechanics for the finite-dimensional case.
\begin{postulate}[The state vectors] \label{pt:state-vect}
    Every non-zero vector of the Hilbert space completely characterizes a possible state of the system, we call such vectors \emph{state vectors}. We thus have that the elements of
    \begin{equation}
        \mathcal{H}_0\coloneqq\mathcal{H}\setminus\{0\}
    \end{equation}
    describe all the possible states of the system.
\end{postulate}
For state vectors, we will also use the Dirac notation writing vectors as $\ket{\psi}$ and their dual as $\bra{\psi}$. An exhaustive treatment of this notation may be found in \cref.

\begin{postulate}[Unitary evolution] \label{pt:unit-evol}
    The state vectors of a closed system evolve only through unitary transformations of the Hilbert space. That is, the time evolution of any state vector $\ket{\psi(t)}$ is given by
    \begin{equation}
        \ket{\psi(t_2)}=\mathrm{U(t_1,t_2)}\ket{\psi(t_1)}
    \end{equation}
    where $U(t_1,t_2)$ is a unitary operator that only depends on $t_1$ and $t_2$.
\end{postulate}
We may interpret this as requiring that the evolution of a closed system preserves the structure we defined on the set $\mathcal{H}$, that is the vector space structure and the inner product space structure. Thus we expect the transformations to be invertible, and linear and to preserve the inner product; in this sense, unitary operators are the automorphisms of the Hilbert space.
\begin{postulate}[Quantum measurements] \label{pt:quant-meas}
    Quantum measurements are described by a collection of pairs $M=\{(\mathrm{M}_x,x)\}_{x\in\mathcal{X}}$ of \emph{measurement operators} $\mathrm{M}_x$ and \emph{outcomes} $x\in\mathcal{X}$ such that the following \emph{completeness equation} is satisfied
    \begin{equation} \label{eq:completeness}
        \sum_{x\in\mathcal{X}}\mathrm{M}_x^\dag\,\mathrm{M}_x=\mathbb{I}
    \end{equation}
    where $\mathbb{I}$ is the identity operator. Then, given a system in a state described by a state vector $\ket{\psi}$, the probability distribution of the outcomes is
    \begin{equation} \label{eq:quant-probability}
        p(x)=\frac{\braket{\psi|\mathrm{M}_x^\dag\,\mathrm{M}_x|\psi}}{\braket{\psi|\psi}}
    \end{equation}
    Finally, any interaction with the system that leads to the measurement of a specific outcome $x$ transforms any state vector $\ket{\psi}$ before the measurement to a new state vector $\ket{\psi'}$ after the measurement according to
    \begin{equation}
        \ket{\psi'}=\mathrm{M}_x\ket{\psi}
    \end{equation}
    that depends on the outcome measured.
\end{postulate}
The probabilities of \cref{eq:quant-probability} are well defined since
\begin{align}
    p(x)&=\frac{\left\lVert\mathrm{M}_x\ket{\psi}\right\rVert^2}{\left\lVert\ket{\psi}\right\rVert^2}\ge 0 \qquad \forall x
    \\
    \sum_{x\in\mathcal{X}}p(x)&=\frac{\braket{\psi|\sum_{x}\mathrm{M}_x^\dag\,\mathrm{M}_x|\psi}}{\braket{\psi|\psi}}=1
\end{align}
We thus have that for any fixed measurement every state vector defines a probability distribution on the outcomes. In this sense, quantum states can be thought of as a generalization of probability distributions.

Quantum measurements define both the probability distributions and the state obtained after the measurement. If we are only interested in the measurement per se we can equate quantum measurements that share the same probability distributions, so that
\begin{equation}
    \mathrm{M}\sim\mathrm{M}' \iff \mathrm{M}_x^\dag\,\mathrm{M}_x=\mathrm{M}_x^{'\dag}\,\mathrm{M}_x' \quad \forall x\in\mathcal{X}
\end{equation}
and the equivalence classes that follow are known as \emph{positive operator-valued measures} (POVMs). Then the following holds
\begin{theorem}[POVMs]
    Positive operator-valued measurements are uniquely determined by a collection of pairs $E=\{(E_x,x)\}_{x\in\mathcal{X}}$ of positive self-adjoint operators and outcomes $x\in\mathcal{X}$ such that
    \begin{equation}
        \sum_{x\in\mathcal{X}}E_x=\mathbb{I}
    \end{equation}
    Given a system in a state described by a state vector $\ket{\psi}$, the probability distribution of the outcomes is
    \begin{equation}
        p(x)=\frac{\braket{\psi|E_x|\psi}}{\braket{\psi|\psi}}
    \end{equation}
    Then the POVM of a quantum measurement M is
    \begin{equation}
        E^{(M)}=\{(E^{(M)}_x=\mathrm{M}_x^\dag\,\mathrm{M}_x,x)\}_{x\in\mathcal{X}}
    \end{equation}
\end{theorem}


\subsubsection{Example: the qubit}
The simplest non-trivial kind of quantum system is the one modeled by the 2-dimensional Hilbert space $\mathcal{H}=\mathbb{C}^2$: the \emph{qubit}. The name refers to the fact that it can be regarded as a quantum version of the classical two-state system, the bit.

To perform explicit calculations we can express $\mathbb{C}^2$ vectors, dual vectors and operators with column vectors, raw vectors and square matrices respectively. Thus, for a fixed orthonormal basis $\{\ket{0},\ket{1}\}$ we can write
\begin{equation}
    \ket{0}=\begin{pmatrix} 1 \\ 0 \end{pmatrix}\quad\ket{1}=\begin{pmatrix} 0 \\ 1 \end{pmatrix}
\end{equation}
so that any state vector $\ket{\psi}=c_0\ket{0}+c_1\ket{1}$ is expressed as
\begin{equation}
    \ket{\psi}=\begin{pmatrix} c_0 \\ c_1 \end{pmatrix}\quad\mathrm{with}\quad c_i\in\mathbb{C}
\end{equation}
Then any operator $O$ is represented by a $2\times2$ complex matrix
\begin{equation}
    O=\begin{pmatrix} c_{1,1} & c_{1,2}\\ c_{2,1} & c_{2,2} \end{pmatrix}\quad\mathrm{with}\quad c_{i,j}\in\mathbb{C}
\end{equation}

Self-adjoint operators are the Hermitian matrices, i.e., matrices equal to their conjugate transpose. A well-known real basis for $2\times2$ Hermitian matrices is the following
\begin{equation}
    \mathds{1}=\begin{pmatrix} 1 & 0\\ 0 & 1 \end{pmatrix}\quad\sigma_1=\begin{pmatrix} 0 & 1\\ 1 & 0 \end{pmatrix}\quad\sigma_2=\begin{pmatrix} 0 & -i\\ i & 0 \end{pmatrix}\quad\sigma_3=\begin{pmatrix} 1 & 0\\ 0 & -1 \end{pmatrix}
\end{equation}
where $\mathds{1}$ is the identity matrix and $\sigma_i$ are the Pauli matrices. Any self-adjoint operator $A$ can thus be expressed as
\begin{align}
    A&=a_0\mathds{1}+a_1\sigma_1+a_2\sigma_2+a_3\sigma_3=a_0\mathds{1}+\Vec{a}\cdot\Vec{\sigma},\quad\Vec{a}=(a_1,a_2,a_3)
\end{align}
where $a_0\in\mathbb{R}$ and $\Vec{a}\in\mathbb{R}^3$.

Unitary operators are the $2\times2$ unitary matrices, i.e., invertible matrices whose inverse is equal to their conjugate transpose. Then they form a group under matrix multiplication so that any unitary matrix $U$ can be expressed as
\begin{equation}
    U=e^{iA}\quad\mathrm{with}\quad A=A^\dag
\end{equation}
and thus the general unitary evolution of a qubit is given by
\begin{align}
    U&=\mathrm{exp}\left[i(a_0\mathds{1}+\Vec{a}\cdot\Vec{\sigma})\right]=\mathrm{exp}\left[i\alpha\mathds{1}\right]\cdot \mathrm{exp}\left[i\frac{\theta}{2}\Hat{n}\cdot\Vec{\sigma}\right]
    \\
    &=e^{i\alpha}\left(\cos\frac{\theta}{2}\mathds{1}+i\sin\frac{\theta}{2}\Hat{n}\cdot\Vec{\sigma}\right)
\end{align}
where we used the notation $\alpha=a_0$, $\frac{\theta}{2}=\lVert\Vec{a}\rVert$ and $\Hat{n}=\frac{\Vec{a}}{\lVert\Vec{a}\rVert}$ that will be useful later on.

Finally, the positive operators of POVMs are the positive semidefinite matrices, i.e., Hermitian matrices whose eigenvalues are all non-negative. For $2\times2$ matrices, this means that the determinant and the trace are non-negative.


\subsection{PVM and observables}
There is a special class of quantum measurements we will be interested in: projection-valued measurements (PVM). PVMs are quantum measurements where the measurement operators $\{P_x\}$ are required to be orthogonal projectors, i.e.
\begin{align}
    P_x^\dag&=P_x \qquad \forall x
    \\
    P_x^2&=P_x \qquad \forall x
\end{align}
and to form a complete set of orthogonal projectors
\begin{align}
    P_x\,P_y&=\delta_{xy}P_x \qquad \forall x,y \label{eq:ortnorm-pro}
    \\
    \sum_{x}P_x&=\mathbb{I} \label{eq:complete-pro}
\end{align}
To understand these definitions we first state an important theorem from linear algebra about self-adjoint operators, a complete treatment and proof can be found in \cref.
\begin{theorem}[Spectral theorem] \label{th:spectral}
    Let $\mathcal{H}$ be a finite-dimensional complex Hilbert space and $\mathrm{A}$ a self-adjoint operator on $\mathcal{H}$. Then there exists an orthonormal basis of eigenvectors of $\mathrm{A}$ with real eigenvalues.
\end{theorem}
This means that for any self-adjoint operator, we may decompose the Hilbert space in orthogonal linear subspaces of eigenvectors with the same eigenvalue, the \emph{eigenspaces}.

For any orthogonal projector $P$, we can show that
\begin{align}
    P\ket{\psi}=\lambda\ket{\psi} &\implies P^2\ket{\psi}=\lambda^2\ket{\psi}=P\ket{\psi}=\lambda\ket{\psi} \notag
    \\
    &\implies \lambda^2=\lambda \notag
    \\
    &\implies \lambda=0,1
\end{align}
and, given an orthonormal base of eigenvectors $\{\ket{e_i}\}$ we may partition it into the two subsets $\{\ket{e_j^{(0)}}\}$ and $\{\ket{e_k^{(1)}}\}$ respectively of eigenvectors with eigenvalue 0 and 1. Then by expressing a generic vector as a linear combination of this base, we have that
\begin{equation} \label{eq:proj-decomp}
    \ket{\psi}=\sum_{i}\braket{e_i|\psi}\ket{e_i} \implies P\ket{\psi}=\sum_{k}\braket{e_k^{(1)}|\psi}\ket{e_k^{(1)}}
\end{equation}
so that any orthogonal projector "orthogonally projects" vectors to its eigenspace with eigenvalue 1, which is thus also its image.

We can now recognize that a set of orthonormal projectors is complete when the spaces on which they project are orthogonal (\cref{eq:ortnorm-pro}) and add up to all the Hilbert space (\cref{eq:complete-pro}). With this setting, it can be easily shown that the following corollary holds
\begin{corollary} \label{cr:spect-decomp}
    Any self-adjoint operator $\mathrm{A}$ with eigenvalues $\{\lambda_i\}$ may be expressed in terms of the projectors $P_i$ of its eigenspaces as
    \begin{equation} \label{eq:spect-decomp}
        \mathrm{A}=\sum_{i}\lambda_i\,P_i
    \end{equation}
\end{corollary}

We thus have that, intuitively, PVMs are defined by decomposing the Hilbert space into orthogonal subspaces and then assigning a certain outcome to each one. In fact, if $\ket{\psi_x}$ is in the projected space of $P_x$ the probability distribution of the outcomes will be
\begin{equation}
    p(y)=\frac{\braket{\psi_x|P_y^\dag\,P_y|\psi_x}}{\braket{\psi_x|\psi_x}}=\delta_{xy}
\end{equation}
and also, after the measurement, any state vector is projected onto the subspace of the outcome
\begin{equation}
    \ket{\psi'}=P_x \ket{\psi}
\end{equation}
With this interpretation, it's easy to recognize an interesting property of PVMs: repeating the same PVM multiple times while the Hilbert space is evolving with the identity operator (i.e. is not changing) always leads to identical results. In fact, after the first measurement, if the measured outcome was $x$, we will have that
\begin{equation}
    \ket{\psi'_{(0)}}=P_x \ket{\psi}
\end{equation}
for any initial vector state $\ket{\psi}$. Then, repeating the same measurement, we will have the probability distribution
\begin{equation}
    p(y)=\frac{\braket{\psi|P_x^\dag\,P_y^\dag\,P_y\,P_x|\psi}}{\braket{\psi|P_x^\dag\,P_x|\psi}}=\delta_{xy}
\end{equation}
and so we will get with certainty the same result. After the measurement, we will have the state vector
\begin{equation}
    \ket{\psi'_{(1)}}=P_x P_x \ket{\psi}=P_x \ket{\psi}
\end{equation}
and we can reiterate the same argument for the following measurements.

When considering well-defined measurable properties of a system, we may require repeated measurements to always give the same outcome if the system remains unchanged in between. From this intuitive concept follows the definition of an \emph{observable} as a PVM with real-valued outcomes. Then, from \cref{cr:spect-decomp}, there is a 1-1 relationship between observables and self-adjoint operators through \cref{eq:spect-decomp}, allowing us to identify any observable with its self-adjoint operator
\begin{equation}
    \{P_i,\lambda_i\}\leftrightarrow\mathrm{A}=\sum_{i}\lambda_i\,P_i
\end{equation}
The expectation value of the observable when the system is in a state described by a state vector $\ket{\psi}$ is then given by
\begin{equation}
    \mathrm{E}[A]=\sum_{i}\lambda_i\,p_i=\sum_{i}\lambda_i\frac{\braket{\psi|P_i^\dag\,P_i|\psi}}{\braket{\psi|\psi}}=\frac{\braket{\psi|\mathrm{A}|\psi}}{\braket{\psi|\psi}}
\end{equation}

\subsubsection{Example: the qubit}
We have already seen that any self-adjoint operator $A$ can be expressed as
\begin{equation}
    A=a_0\mathds{1}+\Vec{a}\cdot\Vec{\sigma} \quad\mathrm{with}\quad a_0\in\mathbb{R},\Vec{a}\in\mathbb{R}^3
\end{equation}
and so these also represent the observables of the qubit.

Let us now consider some examples of quantum measurements. In particular, we will consider the problem of discerning between two states of a qubit. This is a first, particular, instance of quantum estimation, a problem that will be of interest in \cref{ch3}.

We start by considering a qubit that we know to be in one of two possible orthonormal states, $\ket{0}$ or $\ket{1}$. Then we can consider a PVM
\begin{equation}
    \{(P_0,\lambda_0),(P_1,\lambda_1)\}:P_0=\ket{0}\bra{0}=\begin{pmatrix} 1 & 0\\ 0 & 0 \end{pmatrix},\,P_1=\ket{1}\bra{1}=\begin{pmatrix} 0 & 0\\ 0 & 1 \end{pmatrix}
\end{equation}
that corresponds to the observable
\begin{equation}
    A=\begin{pmatrix} \lambda_0 & 0\\ 0 & \lambda_1 \end{pmatrix}
\end{equation}
when $\lambda_0$ and $\lambda_1$ are real numbers. Then the probability distributions of the outcomes are
\begin{align*}
    p_{\ket{0}}(\lambda_0)&=\begin{pmatrix} 1 & 0 \end{pmatrix}\cdot\begin{pmatrix} 1 & 0\\ 0 & 0 \end{pmatrix}\cdot\begin{pmatrix} 1 \\ 0 \end{pmatrix}=1
    &
    p_{\ket{0}}(\lambda_1)&=\begin{pmatrix} 1 & 0 \end{pmatrix}\cdot\begin{pmatrix} 0 & 0\\ 0 & 1 \end{pmatrix}\cdot\begin{pmatrix} 1 \\ 0 \end{pmatrix}=0
    \\
    p_{\ket{1}}(\lambda_0)&=\begin{pmatrix} 0 & 1 \end{pmatrix}\cdot\begin{pmatrix} 1 & 0\\ 0 & 0 \end{pmatrix}\cdot\begin{pmatrix} 0 \\ 1 \end{pmatrix}=0
    &
    p_{\ket{1}}(\lambda_1)&=\begin{pmatrix} 0 & 1 \end{pmatrix}\cdot\begin{pmatrix} 0 & 0\\ 0 & 1 \end{pmatrix}\cdot\begin{pmatrix} 0 \\ 1 \end{pmatrix}=1
\end{align*}
so that we can distinguish with certainty between the two states.

Consider now the same problem but where the two states are not orthogonal, for example, $\ket{0}$ and $\ket{+}=\frac{1}{\sqrt{2}}(\ket{0}+\ket{1})$. Then the previous PVM will lead to the following probability distributions
\begin{align*}
    p_{\ket{0}}(\lambda_0)&=1\qquad p_{\ket{0}}(\lambda_1)=0
    \\
    p_{\ket{+}}(\lambda_0)&=\frac{1}{\sqrt{2}}\begin{pmatrix} 1 & 1 \end{pmatrix}\cdot\begin{pmatrix} 1 & 0\\ 0 & 0 \end{pmatrix}\cdot\frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ 1 \end{pmatrix}=\frac{1}{2}
    \\
    p_{\ket{+}}(\lambda_1)&=\frac{1}{\sqrt{2}}\begin{pmatrix} 1 & 1 \end{pmatrix}\cdot\begin{pmatrix} 0 & 0\\ 0 & 1 \end{pmatrix}\cdot\frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ 1 \end{pmatrix}=\frac{1}{2}
\end{align*}
so that if the measured outcome is $\lambda_1$ we are certain that the state was $\ket{+}$, but if the measured outcome is $\lambda_0$ we cannot distinguish them. Thus if the two initial states are equally likely, three times out of four we will not be able to distinguish them and it can be shown that this is the best we can do with a PVM for two non-orthogonal states.

We can improve our results by considering a POVM. In particular, we can consider the following POVM
\begin{gather}
    E=\{(E_1,\,\lambda_1),(E_2,\,\lambda_2),(E_3,\,\lambda_3)\}
    \\
    E_1=\ket{1}\bra{1}=\begin{pmatrix} 0 & 0\\ 0 & 1 \end{pmatrix},\,E_2=\ket{-}\bra{-}=\frac{1}{2}\begin{pmatrix} +1 & -1\\ -1 & +1 \end{pmatrix},\,E_3=\frac{1}{2}\begin{pmatrix} +1 & +1\\ +1 & -1 \end{pmatrix}
\end{gather}
where $\ket{-}=\frac{1}{\sqrt{2}}(\ket{0}-\ket{1})$, orthogonal to $\ket{+}$. Then one can verify that the probability distributions of the outcomes are
\begin{align*}
    p_{\ket{0}}(\lambda_1)&=0\qquad p_{\ket{0}}(\lambda_2)=\frac{1}{2}\qquad p_{\ket{0}}(\lambda_3)=\frac{1}{2}
    \\
    p_{\ket{+}}(\lambda_1)&=\frac{1}{2}\qquad p_{\ket{+}}(\lambda_2)=0\qquad p_{\ket{+}}(\lambda_3)=\frac{1}{2}
\end{align*}
so that half of the time we can distinguish them. It can be shown that this is the best we can do for two non-orthogonal states so that in this sense there is a degree of indistinguishability between non-orthogonal states, similarly to the indistinguishability of probability distributions we discussed in \cref{prob-dist-ind}.

\subsection{Quantum states} \label{sec:quantum-states}
Following \crefrange{pt:state-vect}{pt:quant-meas}, if we are given a state vector for the system, we can determine how it will evolve under unitary evolutions, the probability distributions of the outcomes of quantum measurements, and the vector state we will obtain after those measurements, depending on the outcomes. We may then ask if there are multiple state vectors that yield the same probabilities for any measurement and continue to do so after any unitary evolution or measurement. Such two vectors would be completely equivalent in their predictions, and we can regard them as describing the same quantum state. This leads to an equivalence relation between state vectors, so that quantum states are the equivalence classes.

We start by requiring that two equivalent state vectors have the same probability distributions for any measurement. This means that
\begin{equation}
    \ket{\psi}\sim\ket{\psi'} \iff \frac{\braket{\psi|\mathrm{M}_x^\dag\,\mathrm{M}_x|\psi}}{\braket{\psi|\psi}}=\frac{\braket{\psi'|\mathrm{M}_x^\dag\,\mathrm{M}_x|\psi'}}{\braket{\psi'|\psi'}} \quad \forall x
\end{equation}
for any quantum measurement $\{(M_x,x)\}$. It's easy to see that a sufficient condition is
\begin{equation}\label{eq:equiv-state-vect}
    \exists\,c \ne 0 \in\mathbb{C} :\quad \ket{\psi'}=c\ket{\psi}
\end{equation}
since for any operator $\mathrm{M}_x$
\begin{equation}
    \frac{\braket{\psi'|\mathrm{M}_x^\dag\,\mathrm{M}_x|\psi'}}{\braket{\psi'|\psi'}}=\frac{\lVert c \rVert^2}{\lVert c \rVert^2}\cdot\frac{\braket{\psi|\mathrm{M}_x^\dag\,\mathrm{M}_x|\psi}}{\braket{\psi|\psi}}
\end{equation}
Then by choosing $\mathrm{M}_x=\ket{\psi}\bra{\psi}$, it's easy to show that \cref{eq:equiv-state-vect} is also a necessary condition.

We also note that for any operator $A$
\begin{equation}
    A(c\ket{\psi})=cA\ket{\psi} \quad \forall c\in\mathbb{C}
\end{equation}
so that any operator has a well-defined action on equivalence classes. In particular, this holds for unitary operators and measurement operators, and so two state vectors in the same equivalence class will remain in the equivalence class after any unitary evolution or measurement.

We have thus proved that quantum states are the equivalence classes of
\begin{equation}
    \ket{\psi}\sim\ket{\psi'} \iff \exists\,c \ne 0 \in\mathbb{C} :\quad \ket{\psi'}=c\ket{\psi}
\end{equation}
Then for any state vector $\ket{\psi}$, its quantum state is
\begin{equation}\label{eq:quantum-state}
    \left[\ket{\psi}\right]_\sim=\{c\ket{\psi}\,\forall c\ne 0\in\mathbb{C}\}
\end{equation}
and so the space of quantum states is isomorphic to the set of 1-dim linear subspaces of $\mathcal{H}$, also called \emph{complex lines}. This set is known as the \emph{projective space} of $\mathcal{H}$ and is denoted as $\mathbf{P}\mathcal{H}$. When $\mathcal{H}=\mathbb{C}^N$, the projective space is known as the $n$-dimensional complex projective space $\mathbf{\mathbb{C}P}^n$, where $n=N-1$. Then \cref{eq:quantum-state} leads to the intrinsic definition of a surjective \emph{projection map}
\begin{equation} \label{eq:proj-map-PH}
    \pi:\mathcal{H}_0\to\mathbf{P}\mathcal{H}\quad\pi(\ket{\psi})=[\ket{\psi}]_\sim
\end{equation}
that maps every state vector to its quantum state.

\subsubsection{Example: the qubit}
For the qubit, the projective space is the 1-dimensional complex projective space $\mathbf{\mathbb{C}P}^1$. We can get a sense of the structure of this space considering the expression of a general state vector as a linear combination of an orthonormal basis $\{\ket{0},\ket{1}\}$
\begin{equation}
    \ket{\psi}=c_0\ket{0}+c_1\ket{1}\quad\mathrm{with}\quad c_0=\lVert c_0\rVert e^{i\alpha},\,c_1=\lVert c_1\rVert e^{i\beta}\in\mathbb{C}
\end{equation}
so that $\lVert \ket{\psi} \rVert^2=\lVert c_0\rVert^2+\lVert c_1\rVert^2$. Every state vector with the same quantum state is given by
\begin{equation}
    \ket{\psi'}=c \ket{\psi}\quad\mathrm{with}\quad c=\lVert c \rVert e^{i\gamma}\in\mathbb{C}\setminus\{0\}
\end{equation}
so that the quantum state doesn't depend on the norm and the global phase of the state vector. We can then choose a representative for each quantum state by fixing the norm of the state vector to 1 and the phase of the first coefficient to 0, that is
\begin{equation}
    \ket{\psi}=c_0\ket{0}+c_1\ket{1}\mapsto\frac{\lVert c_0\rVert}{\sqrt{\lVert c_0\rVert^2+\lVert c_1\rVert^2}}\ket{0}+\frac{\lVert c_1\rVert}{\sqrt{\lVert c_0\rVert^2+\lVert c_1\rVert^2}}\,e^{i(\beta-\alpha)}\ket{1}
\end{equation}
so that any quantum state can be represented by a state vector of the form
\begin{equation}
    \ket{\psi}=\cos\frac{\theta}{2}\ket{0}+e^{i\phi}\sin\frac{\theta}{2}\ket{1} \quad\mathrm{with}\quad \theta\in[0,\pi],\,\phi\in\left[0,2\pi\right[
\end{equation}
where we have that when $\theta=0$ or $\theta=\pi$ the expression is independent of $\phi$. Then $\theta$ and $\phi$ can be regarded as the polar coordinates of a 2-sphere of quantum states with the north pole corresponding to $\ket{0}$ and the south pole to $\ket{1}$. This is known as the \emph{Bloch sphere} and is a representation of the projective space $\mathbf{\mathbb{C}P}^1$ for a fixed orthonormal basis.

\subsection{Density operators}\label{sec:density-matrices}
We have seen that quantum states are the 1-dim linear subspaces of $\mathcal{H}$, so we can identify them with some orthogonal projectors. The only additional requirement is that the projected spaces must be 1-dim, i.e., they must be rank-1 orthogonal projectors. From \cref{eq:proj-decomp}, we know that for any rank-1 projector, there must exist a normalized vector $\ket{\tilde{e}}$ such that
\begin{equation}
    P_{\tilde{e}}\ket{\psi}=\braket{\tilde{e}|\psi}\ket{\tilde{e}}\quad\forall\ket{\psi}\in\mathcal{H}_0
\end{equation}
and so from \cref{eq:outer-prod}, we have
\begin{equation}\label{eq:rank1-proj}
    P_{\tilde{e}}=\ket{\tilde{e}}\bra{\tilde{e}}
\end{equation}
In the context of quantum mechanics, the set of rank-1 orthogonal projectors is known as the set of \emph{pure density operators} and is denoted as $\mathfrak{D}$.

We now define a candidate for the \emph{projection map} to pure density operators
\begin{equation} \label{eq:proj-map-D}
    \Pi:\mathcal{H}_0\to\mathfrak{D}\quad\Pi(\ket{\psi})=\frac{\ket{\psi}\bra{\psi}}{\braket{\psi|\psi}}\coloneq \rho_\psi
\end{equation}
This map is well-defined since for every $\ket{\psi}$ we have that $\rho_\psi$ is self-adjoint, idempotent and
\begin{equation}
    \rho_\psi=\frac{\ket{\psi}\bra{\psi}}{\braket{\psi|\psi}}=(\frac{1}{\lVert\ket{\psi}\rVert}\ket{\psi})(\bra{\psi}\frac{1}{\lVert\ket{\psi}\rVert})
\end{equation}
so that it is of rank 1.
This map also has a well-defined action on quantum states since
\begin{equation}
    \frac{(c\ket{\psi})(\bra{\psi}c^*)}{(\bra{\psi}c^*)(c\ket{\psi})}=\frac{\ket{\psi}\bra{\psi}}{\braket{\psi|\psi}}\quad\forall c\ne 0\in\mathbb{C}
\end{equation}
so that it defines the map
\begin{equation}
    f:\mathbf{P}\mathcal{H}\to\mathfrak{D}\quad f([\ket{\psi}]_\sim)=\Pi(\ket{\psi})=\rho_\psi
\end{equation}
Finally, we can prove that $f$ is invertible, allowing us to identify quantum states with density matrices. The map is 1-1 since given any two state vectors $\ket{\psi}$ and $\ket{\phi}$, we have that
\begin{align*}
    \rho_\psi=\rho_\phi &\implies \rho_\psi\,\rho_\phi=\rho_\phi
    \\
    &\implies \frac{\ket{\psi}\braket{\psi|\phi}\bra{\phi}}{\braket{\psi|\psi}\braket{\phi|\phi}}=\frac{\ket{\phi}\bra{\phi}}{\braket{\phi|\phi}}
    \\
    &\implies \frac{\braket{\psi|\phi}}{\braket{\psi|\psi}}\ket{\psi}=\ket{\phi}
    \\
    &\implies \ket{\psi} \sim \ket{\phi}
\end{align*}
Then, since any rank-1 orthogonal projector can be expressed as in \cref{eq:rank1-proj}, we also have that $f$ is surjective. We have thus proved that
\begin{equation}
    \mathbf{P}\mathcal{H}\sim\mathfrak{D}
\end{equation}
through the intrinsic map $f$, so we may identify quantum states with pure density operators, and the two projection maps $\pi$ and $\Pi$ are the same under this identification.

We now want to restate \crefrange{pt:state-vect}{pt:quant-meas} in terms of pure density matrices. To do so, we will need the concept of the trace of an operator. For a finite-dimensional Hilbert space, we may define the trace of an operator $A$ as the linear functional
\begin{equation}\label{eq:trace}
    \mathrm{tr}(A)=\sum_{i}\braket{e_i|A|e_i},\quad\{\ket{e_i}\}\,\mathrm{o.n. basis}
\end{equation}
where it can be shown that the expression on the right is independent of the choice of the orthonormal basis. The trace also has the following cyclic property
\begin{equation}
    \mathrm{tr}(AB)=\mathrm{tr}(BA)
\end{equation}
so that for any number of operators $A_1,\dots,A_n$, we have
\begin{equation}
    \mathrm{tr}(A_1\dots A_n)=\mathrm{tr}(A_nA_1\dots A_{n-1})
\end{equation}
We also have the following result from linear algebra
\begin{theorem}
    Let $\mathcal{H}$ be a finite-dimensional complex Hilbert space and $\mathrm{A}$ any self-adjoint operator on $\mathcal{H}$. Then
    \begin{equation}
        \mathrm{tr}(A)=\sum_{i}\lambda_i
    \end{equation}
    where $\{\lambda_i\}$ are the eigenvalues of $\mathrm{A}$ repeated according to their algebraic multiplicity.
\end{theorem}

One immediate consequence of this theorem is that an orthogonal projector is of rank 1 if and only if it has a unitary trace. Then we may equivalently define pure density operators in the following, more common, way
\begin{equation}
    \mathfrak{D}\coloneq\{\rho\in\mathfrak{L}\mid\rho^\dag=\rho,\,\rho^2=\rho,\,\mathrm{tr}(\rho)=1\}
\end{equation}
We can now reformulate \cref{pt:state-vect} as
\setcounter{postulate}{0}\begin{postulate}[Quantum states]
    The set of all the possible quantum states of a system is the projective space of the system's Hilbert space. Then every quantum state is uniquely determined by a pure density operator $\rho\in\mathfrak{D}$
\end{postulate}

Given a unitary evolution of the system, we can compute the evolution of any density operator as follows. Any initial quantum state can be expressed as
\begin{equation}
    \rho(t_1)=\ket{\psi(t_1)}\bra{\psi(t_1)}
\end{equation}
where $\ket{\psi(t_1)}$ is a normalized state vector, then for any unitary evolution $U(t_1,t_2)$ we have that $\ket{\psi(t_2)}$ remains normalized and
\begin{align*}
    \rho(t_2)&=\ket{\psi(t_2)}\bra{\psi(t_2)}
    \\
    &=U(t_1,t_2)\ket{\psi(t_1)}\bra{\psi(t_1)}U^\dag(t_1,t_2)
    \\
    &=U(t_1,t_2)\rho(t_1)U^\dag(t_1,t_2)
\end{align*}
so that we can reformulate \cref{pt:unit-evol} as
\begin{postulate}[Unitary evolution]
    The Hilbert space of a closed system evolves only through unitary transformations. Coherently, the time evolution of any pure density operator $\rho(t)$ describing the quantum state of the system is given by
    \begin{equation}
        \rho(t_2)=U(t_1,t_2)\rho(t_1)U^\dag(t_1,t_2)
    \end{equation}
    where $U(t_1,t_2)$ is a unitary operator that only depends on $t_1$ and $t_2$.
\end{postulate}

Given any quantum measurement $\{(\mathrm{M}_x,x)\}$ and a quantum state $\rho$ we have that
\begin{equation}
    \rho=\ket{\psi}\bra{\psi} \implies p(x)=\braket{\psi|M_x^\dag\,M_x|\psi}=\lVert M_x\ket{\psi}\rVert^2
\end{equation}
for some normalized state vector $\ket{\psi}$. Then by choosing
\begin{equation}
    \frac{M_x\ket{\psi}}{\lVert M_x\ket{\psi}\rVert}
\end{equation}
 as the first element of an orthonormal basis, we have that
\begin{equation}
    \mathrm{tr}(M_x\,\rho\,M_x^\dag)=\frac{\braket{\psi|M_x^\dag\,M_x|\psi}\braket{\psi|M_x\,M_x^\dag|\psi}}{\lVert M_x\ket{\psi}\rVert^2}=\lVert M_x\ket{\psi}\rVert^2
\end{equation}
so that we can reformulate \cref{pt:quant-meas} as
\begin{postulate}[Quantum measurements]
    Quantum measurements are described by a collection of pairs $\{(\mathrm{M}_x,x)\}$ of \emph{measurement operators} $\mathrm{M}_x$ and \emph{outcomes} $x$ such that the following \emph{completeness equation} is satisfied
    \begin{equation}
        \sum_{x}\mathrm{M}_x^\dag\,\mathrm{M}_x=\mathbb{I}
    \end{equation}
    where $\mathbb{I}$ is the identity operator. Then, given a system in a quantum state described by a pure density operator $\rho$, the probability distribution of the outcomes is
    \begin{equation}
        p(x)=\mathrm{tr}(M_x\,\rho\,M_x^\dag)
    \end{equation}
    Finally, any interaction with the system that leads to the measurement of a specific outcome $x$ transforms the quantum state $\rho$ before the measurement to a new quantum state $\rho'$ after the measurement according to
    \begin{equation}
        \rho'=\frac{M_x\,\rho\,M_x^\dag}{\mathrm{tr}(M_x\,\rho\,M_x^\dag)}
    \end{equation}
    that depends on the outcome measured.
\end{postulate}

At last, we have that the expectation value of an observable $A$ when the system is in a quantum state described by a pure density operator $\rho$ is
\begin{equation}
    \mathrm{E}[A]=\sum_{i}\lambda_i\,\mathrm{tr}(P_i\,\rho\,P_i^\dag)=\mathrm{tr}(\rho\,A)
\end{equation}

\subsubsection{Example: the qubit}
Pure density operators for the qubit are the self-adjoint operators with one eigenvalue equal to 1 and the other equal to 0. Then pure density operators are represented by $2\times2$ Hermitian matrices with trace 1 and determinant 0. Expressing a generic Hermitian matrix $A$ as in \cref{pauli-rep} it can be shown that
\begin{equation}
    \mathrm{tr}(A)=2a_0\qquad\mathrm{det}(A)=a_0^2-\lVert\Vec{a}\rVert^2
\end{equation}
so that for any pure density operator, we have that $a_0=\frac{1}{2}$ and $\lVert\Vec{a}\rVert=\frac{1}{2}$. Then we can represent any pure density operator as
\begin{equation}
    \rho=\frac{\mathds{1}+\Vec{n}\cdot\Vec{\sigma}}{2}\quad\mathrm{with}\quad\Vec{n}\in\mathbb{R}^3:\,\lVert\Vec{n}\rVert=1
\end{equation}
where we recognize the Bloch sphere representation of the quantum states of the qubit.